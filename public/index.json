
[{"content":"gibby /g…™b.i:/ .n 1 software engineer 2 information superhighway denizen\n","date":"17 May 2024","externalUrl":null,"permalink":"/","section":"","summary":"gibby /g…™b.","title":"","type":"page"},{"content":"","date":"17 May 2024","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"Devops","type":"tags"},{"content":"","date":"17 May 2024","externalUrl":null,"permalink":"/tags/guide/","section":"Tags","summary":"","title":"Guide","type":"tags"},{"content":"","date":"17 May 2024","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"Recently, I\u0026rsquo;ve been grappling with Docker containers. When I build a dockerfile via docker build, my host machine has limited visibility into the containerized build process.\nThis is by Docker design, but still presents a challenge if I want to monitor Docker builds at scale.\nI can move monitoring into the dockerfile itself, but then I run into another issue - how do I pull relevant artifacts out of the resulting Docker image? Bonus points if I can extract these artifacts without running Docker.\nInfo\nA Dockerfile contains a sequence of build instructions executed within an isolated (containerized) environment. These instructions generate a Docker image, which serve as a blueprint for container creation.\nWhen an image is executed, Docker creates a container based on the image, effectively reproducing the environment defined in the Dockerfile.\nEach instruction in a Dockerfile corresponds to an image layer. A given layer contains the delta between the current layer and the previous one, usually representing a change in the underlying container\u0026rsquo;s file system or configuration.\nSetting up a Docker image # Let\u0026rsquo;s start by building a Docker image. Here\u0026rsquo;s my motivating example:\nFROM rust:1.76.0-alpine3.18 RUN apk update \u0026amp;\u0026amp; apk add strace COPY . . WORKDIR /app RUN strace -o trace.log cargo run This dockerfile copies an application into the Docker build context and traces the application\u0026rsquo;s build with strace. strace will output its logfile to trace.log.\nLet\u0026rsquo;s say I\u0026rsquo;m tracing my build with strace because my Rust project is open-source and frequently integrates new open-source dependencies. To protect myself from supply chain attacks, I want to watch for suspicious network calls when my app is executed. The only way to collect this information from the Docker build is by running strace from within the container.\nThe problem # \u0026hellip;But then how do we actually get our hands on trace.log? We could docker run the container and search its file system manually. But what if I\u0026rsquo;m trying to integrate this check into my CI pipeline? Can this process be automated?\nThis general problem applies to any scenario where your Dockerfile produces some artifact that you\u0026rsquo;d like to extract from the resulting container.\nI\u0026rsquo;m personally interested in this tracing example because a command like strace -o trace.log docker build -f Dockerfile . doesn\u0026rsquo;t produce an interesting trace.log, due to the containerized build process that I mentioned earlier.\nThe solution # First, build and save the Docker image:\ndocker build -f Dockerfile -t myimage:1.0 . docker save -o myimage.tar myimage:1.0 This docker build command builds the Dockerfile in the current directory (.) and tags the resulting image with myimage:1.0. docker save compresses the image to a .tar file - these .tar files are typically used to distribute, deploy, and/or backup Docker images. For my case, docker save will save the image in a more easily dissectible format.\nI\u0026rsquo;ll extract the image tarball to a clean output directory:\nmkdir myimage tar -xvf myimage.tar -C myimage Once extracted, here are the contents of myimage:\nüìÅmyimage ‚îî‚îÄ‚îÄ üìÅblobs ‚îî‚îÄ‚îÄ üìÅsha256 ‚îî‚îÄ‚îÄ 1fc818d7122c2955f10c33a86a84be0585dce8264f07ff20d26d6e4d77072689 ‚îî‚îÄ‚îÄ 5500516daa5d159d01f04ea168438de6cbc4a86197cf3b462b7f00e1054f1fe6 ‚îî‚îÄ‚îÄ 5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef ‚îî‚îÄ‚îÄ 60be3224167df7d3927eef73eab4d9fbac87c2ad227db7302f62c715ee1aedcf ‚îî‚îÄ‚îÄ 79643e31b5e64ee2c97c3fada467f944d97691b15beeabd27d60bb24dcf62958 ‚îî‚îÄ‚îÄ 807a30def12c95b7638d81513f8ff014b82e0be9b02c3a2741a2de417afff353 ‚îî‚îÄ‚îÄ aedc3bda2944bb9bcb6c3d475bee8b460db9a9b0f3e0b33a6ed2fd1ae0f1d445 ‚îî‚îÄ‚îÄ b7da1d95051fa9e21f5c9934d4abb8686038e4d76775c857a39644fc3a7b8e81 ‚îî‚îÄ‚îÄ b88b8a4eae96dcec86268cf8c5b53dac6c263430682a7f1705e35eb34f5b4a5a ‚îî‚îÄ‚îÄ cb35dc109a5e6c8f76a05a26ae1178fc7489ddf690110600dc0b60ea05d371c0 ‚îî‚îÄ‚îÄ d708bd3ae8e28161aa0fa6207912621fd352c1126593347982cde1a2e609ac14 ‚îî‚îÄ‚îÄ dcc8140df88f28d0f2807d30bae4a76c2d597e1dda6f98274d37c5bfc0e9dd06 ‚îî‚îÄ‚îÄ dd4e2e76f6fc4791b1dd86cee52df664163fd809ed59bd9eb2181a4db94b65a2 ‚îî‚îÄ‚îÄ e78fc723f9dec6ad6c8cdac73bd8df9c477b3fe62741df0b2e6112d47b35c132 ‚îî‚îÄ‚îÄ f0a1565b3b4d7c42ab9ad5f613fecdf9c84a493e5c31ee7c155b45e74b5f17d4 ‚îî‚îÄ‚îÄ f53c508663464b69bf26e90bc5d916b171aa7c946ddc9c6b761aeaed2839996e ‚îî‚îÄ‚îÄ index.json ‚îî‚îÄ‚îÄ manifest.json ‚îî‚îÄ‚îÄ oci-layout ‚îî‚îÄ‚îÄ repositories Each of these (extensionless) hashed files under blobs/sha256 represent a layer in the Docker image. I\u0026rsquo;m guaranteed to find trace.log somewhere in this forest of layers.\nNaive approach # Knowing this, I might try to find strace.log with brute force. I can just extract every layer under blobs/sha256, then recursively search all child directories for strace.log.\nI can try automating this procedure with a script like this:\n#!/bin/bash BLOBS_DIR=\u0026#34;./myimage/blobs/sha256\u0026#34; # Attempt extraction on all extensionless files for file in \u0026#34;$BLOBS_DIR\u0026#34;/*; do if [ -f \u0026#34;$file\u0026#34; ]; then echo \u0026#34;Attempting extraction of $file...\u0026#34; tar -xf \u0026#34;$file\u0026#34; -C \u0026#34;$BLOBS_DIR\u0026#34; fi done # Search for trace.log in the blobs directory find \u0026#34;$BLOBS_DIR\u0026#34; -type f -name \u0026#34;trace.log\u0026#34; When I run this script, I encounter this error for a few of the layers: tar: This does not look like a tar archive but the script continues on and trace.log is eventually located. Yay!\nAlthough this approach works for this simple case, there are some drawbacks.\nMy image is based on a lightweight alpine image, but if I were using a beefier ubuntu image then this script might take a very long time to execute. This is because the base image itself is also contained within blobs/sha256, so locating trace.log involves extracting layers that contain the image base\u0026rsquo;s file system.\nNote\nWhen experimenting with this approach in a CI environment, I wanted to cleanup $BLOBS_DIR to prevent the unpacked tarball from leaking into my build artifacts. I ran into ownership-related errors when trying to delete base image files form $BLOBS_DIR. This may have been an issue specific to my build system though.\nBetter approach # It\u0026rsquo;s possible to locate strace.log and extract a single layer of the image - i.e., no unnecessary extractions. To do this, we need to leverage some knowledge of the OCI Image Specification to decode the contents of myimage.tar.\nFirst, I\u0026rsquo;ll reference the OCI image manifest spec to understand more about manifest.json. My image\u0026rsquo;s manifest.json looks like this:\n[ { \u0026#34;Config\u0026#34;: \u0026#34;blobs/sha256/b88b8a4eae96dcec86268cf8c5b53dac6c263430682a7f1705e35eb34f5b4a5a\u0026#34;, \u0026#34;RepoTags\u0026#34;: [ \u0026#34;myimage:1.0\u0026#34; ], \u0026#34;Layers\u0026#34;: [ \u0026#34;blobs/sha256/aedc3bda2944bb9bcb6c3d475bee8b460db9a9b0f3e0b33a6ed2fd1ae0f1d445\u0026#34;, \u0026#34;blobs/sha256/5500516daa5d159d01f04ea168438de6cbc4a86197cf3b462b7f00e1054f1fe6\u0026#34;, \u0026#34;blobs/sha256/cb35dc109a5e6c8f76a05a26ae1178fc7489ddf690110600dc0b60ea05d371c0\u0026#34;, \u0026#34;blobs/sha256/79643e31b5e64ee2c97c3fada467f944d97691b15beeabd27d60bb24dcf62958\u0026#34;, \u0026#34;blobs/sha256/1fc818d7122c2955f10c33a86a84be0585dce8264f07ff20d26d6e4d77072689\u0026#34;, \u0026#34;blobs/sha256/5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\u0026#34;, \u0026#34;blobs/sha256/d708bd3ae8e28161aa0fa6207912621fd352c1126593347982cde1a2e609ac14\u0026#34; ], \u0026#34;LayerSources\u0026#34;: { \u0026#34;sha256:1fc818d7122c2955f10c33a86a84be0585dce8264f07ff20d26d6e4d77072689\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 103592960, \u0026#34;digest\u0026#34;: \u0026#34;sha256:1fc818d7122c2955f10c33a86a84be0585dce8264f07ff20d26d6e4d77072689\u0026#34; }, \u0026#34;sha256:5500516daa5d159d01f04ea168438de6cbc4a86197cf3b462b7f00e1054f1fe6\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 138808320, \u0026#34;digest\u0026#34;: \u0026#34;sha256:5500516daa5d159d01f04ea168438de6cbc4a86197cf3b462b7f00e1054f1fe6\u0026#34; }, \u0026#34;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 1024, \u0026#34;digest\u0026#34;: \u0026#34;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\u0026#34; }, \u0026#34;sha256:79643e31b5e64ee2c97c3fada467f944d97691b15beeabd27d60bb24dcf62958\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 4128256, \u0026#34;digest\u0026#34;: \u0026#34;sha256:79643e31b5e64ee2c97c3fada467f944d97691b15beeabd27d60bb24dcf62958\u0026#34; }, \u0026#34;sha256:aedc3bda2944bb9bcb6c3d475bee8b460db9a9b0f3e0b33a6ed2fd1ae0f1d445\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 7629824, \u0026#34;digest\u0026#34;: \u0026#34;sha256:aedc3bda2944bb9bcb6c3d475bee8b460db9a9b0f3e0b33a6ed2fd1ae0f1d445\u0026#34; }, \u0026#34;sha256:cb35dc109a5e6c8f76a05a26ae1178fc7489ddf690110600dc0b60ea05d371c0\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 672828928, \u0026#34;digest\u0026#34;: \u0026#34;sha256:cb35dc109a5e6c8f76a05a26ae1178fc7489ddf690110600dc0b60ea05d371c0\u0026#34; }, \u0026#34;sha256:d708bd3ae8e28161aa0fa6207912621fd352c1126593347982cde1a2e609ac14\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.oci.image.layer.v1.tar\u0026#34;, \u0026#34;size\u0026#34;: 4483072, \u0026#34;digest\u0026#34;: \u0026#34;sha256:d708bd3ae8e28161aa0fa6207912621fd352c1126593347982cde1a2e609ac14\u0026#34; } } } ] Notice that there are far fewer layers listed under Layers than I saw in myimage/blobs/sha256 earlier. The manifest has filtered out any \u0026ldquo;empty\u0026rdquo; layers - i.e., layers that apply environmental changes but don\u0026rsquo;t modify the file system.\nFurthermore, the \u0026ldquo;layer\u0026rdquo; listed as the manifest\u0026rsquo;s Config isn\u0026rsquo;t a layer at all. This Config value is a pointer to the image\u0026rsquo;s config.json. (This Config path would have produced a tar: This does not look like a tar archive error like we saw with the naive approach.)\nI can read this image\u0026rsquo;s config.json by running this command:\ncat myimage/blobs/sha256/b88b8a4eae96dcec86268cf8c5b53dac6c263430682 a7f1705e35eb34f5b4a5a \u0026gt; config.json The config.json looks like this:\n{ \u0026#34;architecture\u0026#34;: \u0026#34;amd64\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;, \u0026#34;RUSTUP_HOME=/usr/local/rustup\u0026#34;, \u0026#34;CARGO_HOME=/usr/local/cargo\u0026#34;, \u0026#34;RUST_VERSION=1.76.0\u0026#34; ], \u0026#34;Cmd\u0026#34;: [ \u0026#34;/bin/sh\u0026#34; ], \u0026#34;WorkingDir\u0026#34;: \u0026#34;/app\u0026#34; }, \u0026#34;created\u0026#34;: \u0026#34;2024-05-13T17:06:51.253198519Z\u0026#34;, \u0026#34;history\u0026#34;: [ { \u0026#34;created\u0026#34;: \u0026#34;2024-01-27T00:30:56.150825642Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;/bin/sh -c #(nop) ADD file:8729f9c0258836b640e9e789c7ab029cf4547e0596557d54dd4a4d7d8e4a785f in / \u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-01-27T00:30:56.304681072Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;/bin/sh -c #(nop) CMD [\\\u0026#34;/bin/sh\\\u0026#34;]\u0026#34;, \u0026#34;empty_layer\u0026#34;: true }, { \u0026#34;created\u0026#34;: \u0026#34;2024-03-11T15:56:03Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;RUN /bin/sh -c apk add --no-cache ca-certificates gcc # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-03-11T15:56:03Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;ENV RUSTUP_HOME=/usr/local/rustup CARGO_HOME=/usr/local/cargo PATH=/usr/local/cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin RUST_VERSION=1.76.0\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34;, \u0026#34;empty_layer\u0026#34;: true }, { \u0026#34;created\u0026#34;: \u0026#34;2024-03-11T15:56:03Z\u0026#34;, \u0026#34;created_by\u0026#34;:\u0026#34;RUN /bin/sh -c set -eux; apkArch=\\\u0026#34;$(apk --print-arch)\\\u0026#34;; case \\\u0026#34;$apkArch\\\u0026#34; in x86_64) rustArch=\u0026#39;x86_64-unknown-linux-musl\u0026#39;; rustupSha256=\u0026#39;b9d84cbba1ed29d11c534406a1839d64274d29805041e0e096d5293ae6390dd0\u0026#39; ;; aarch64) rustArch=\u0026#39;aarch64-unknown-linux-musl\u0026#39;; rustupSha256=\u0026#39;841513f7599fcf89c71a62dea332337dfd4332216b60c17648d6effbeefe66a9\u0026#39; ;; *) echo \\u003e\\u00262 \\\u0026#34;unsupported architecture: $apkArch\\\u0026#34;; exit 1 ;; esac; url=\\\u0026#34;https://static.rust-lang.org/rustup/archive/1.27.0/${rustArch}/rustup-init\\\u0026#34;; wget \\\u0026#34;$url\\\u0026#34;; echo \\\u0026#34;${rustupSha256} *rustup-init\\\u0026#34; | sha256sum -c -; chmod +x rustup-init; ./rustup-init -y --no-modify-path --profile minimal --default-toolchain $RUST_VERSION --default-host ${rustArch}; rm rustup-init; chmod -R a+w $RUSTUP_HOME $CARGO_HOME; rustup --version; cargo --version; rustc --version; # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-05-13T17:06:49.659900887Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;RUN /bin/sh -c apk update \\u0026\\u0026 apk add strace # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-05-13T17:06:49.823538715Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;COPY . . # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-05-13T17:06:49.852497547Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;WORKDIR /app\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; }, { \u0026#34;created\u0026#34;: \u0026#34;2024-05-13T17:06:51.253198519Z\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;RUN /bin/sh -c strace -o trace.log cargo run # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; } ], \u0026#34;os\u0026#34;: \u0026#34;linux\u0026#34;, \u0026#34;rootfs\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;diff_ids\u0026#34;: [ \u0026#34;sha256:aedc3bda2944bb9bcb6c3d475bee8b460db9a9b0f3e0b33a6ed2fd1ae0f1d445\u0026#34;, \u0026#34;sha256:5500516daa5d159d01f04ea168438de6cbc4a86197cf3b462b7f00e1054f1fe6\u0026#34;, \u0026#34;sha256:cb35dc109a5e6c8f76a05a26ae1178fc7489ddf690110600dc0b60ea05d371c0\u0026#34;, \u0026#34;sha256:79643e31b5e64ee2c97c3fada467f944d97691b15beeabd27d60bb24dcf62958\u0026#34;, \u0026#34;sha256:1fc818d7122c2955f10c33a86a84be0585dce8264f07ff20d26d6e4d77072689\u0026#34;, \u0026#34;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef\u0026#34;, \u0026#34;sha256:d708bd3ae8e28161aa0fa6207912621fd352c1126593347982cde1a2e609ac14\u0026#34; ] } } The most important part of this file is the history array. Each entry in the history array corresponds to a layer, and each entry\u0026rsquo;s created_by indicates which build command produced it. If a layer is created_by a command like touch readme.txt, then this layer .tar will contain readme.txt.\nIn the above history array, the entry where created_by contains \u0026ldquo;-o trace.log\u0026rdquo; describes a layer that contains trace.log. This is the precise layer that I want to extract.\nTo map each layer to its sha256 hash, filter out all layers where empty_layer=true. The remaining entries in history correspond to each hash listed in rootfs.diff_ids - meaning history[n] corresponds to rootfs.diff_ids[n].\nOnce I have the layer\u0026rsquo;s hash, I can proceed with extracting the layer and pulling out trace.log.\nI wrote a script which automates this entire process, given myimage.tar:\n#!/bin/bash # Extract myimage.tar to a clean directory mkdir myimage tar -xvf myimage.tar -C myimage # Write config.json configPath=$(jq -r \u0026#39;.[0].Config\u0026#39; myimage/manifest.json) cat myimage/$configPath \u0026gt; myimage/config.json # Read myimage/config.json and filter out empty_layer history entries history=$(jq -c \u0026#39;.history[] | select(.empty_layer != true)\u0026#39; myimage/config.json) historyArray=($(echo $history | jq -r \u0026#39;.[]\u0026#39;)) # Find the index of the history entry where created_by contains \u0026#39;-o strace.log\u0026#39; index=-1 for i in \u0026#34;${!historyArray[@]}\u0026#34;; do if [[ ${historyArray[i]} == *\u0026#34;-o strace.log\u0026#34;* ]]; then index=$i break fi done # Read rootfs.diff_ids and get the entry at the same index rootfs=$(jq -r \u0026#34;.rootfs.diff_ids[$index]\u0026#34; myimage/config.json) # Strip the sha256: prefix rootfs=$(echo $rootfs | sed \u0026#39;s/sha256://\u0026#39;) # Extract the trace.log\u0026#39;s layer into a clean directory mkdir $rootfs tar -xvf myimage/blobs/sha256/$rootfs -C $rootfs # Find trace.log in myimage/$rootfs and move it into this script\u0026#39;s directory script_dir=$(dirname \u0026#34;$0\u0026#34;) find $rootfs -name \u0026#39;trace.log\u0026#39; -exec mv {} \u0026#34;$script_dir\u0026#34; \\; # Cleanup rm -rf myimage rm -rf $rootfs This script is dependent on jq, which is a command-line JSON parser.\nPost-script: ye olde Docker image spec # Prior to adopting the OCI specification with Docker 1.11, Docker had its own image spec.\nMy original solution was written for the older Docker image spec, since I was working with build systems that used an older version of Docker. If you follow these steps with Docker \u0026lt;1.11, these .json files will be shaped a little differently. The same approach still works though.\nHere\u0026rsquo;s are the key differences that I noticed with the Docker image spec:\nHashes correspond to directories instead of files, and each hash directory contains a layer.tar. Hash directories are at the top-level of the image. config.json is a {sha256hash}.json file in the top-level of the tarball. Layer hashes can\u0026rsquo;t be translated using the rootfs.diff_ids. Once empty layers are filtered out, history[n] corresponds to manifest.json\u0026rsquo;s layers[n]. I\u0026rsquo;ve adopted the script above for Docker image specs here:\n#!/bin/bash # Extract myimage.tar to a clean directory mkdir myimage tar -xvf nc-janitor.tar -C myimage # Write config.json configPath=$(echo $manifestJson | jq -r \u0026#39;.[0].Config\u0026#39;) configJson=$(jq \u0026#39;.\u0026#39; $tempDir/$config) # Read myimage/config.json and filter out empty_layer history entries history=$(echo $configJson | jq -c \u0026#39;.history[] | select(.empty_layer != true)\u0026#39;) # Find the index of the history entry with -o strace.log historyArray=($(echo $history | jq -r \u0026#39;.[]\u0026#39;)) index=-1 for i in \u0026#34;${!historyArray[@]}\u0026#34;; do if [[ ${historyArray[i]} == *\u0026#34;codeql database create\u0026#34;* ]]; then index=$i break fi done # Find the layer tarball that corresponds to the index we found above layer=$(echo $manifestJson | jq -r \u0026#34;.layers[$index].digest\u0026#34;) # Extract the artifact\u0026#39;s layer into a clean directory mkdir output tar -xvf myimage/$layer/layer.tar -C $tempDir/$layer # Find trace.log in myimage/$rootfs and move it to the script\u0026#39;s directory script_dir=$(dirname \u0026#34;$0\u0026#34;) find $rootfs -name \u0026#39;trace.log\u0026#39; -exec mv {} \u0026#34;$script_dir\u0026#34; \\; # Cleanup rm -rf myimage rm -rf output (I\u0026rsquo;m not totally sure about the stability of Docker\u0026rsquo;s image spec, but this script works for me on image tarballs saved with Docker v1.2.)\n","date":"17 May 2024","externalUrl":null,"permalink":"/posts/docker_extraction/","section":"Posts","summary":"If a dockerfile is built in a container and no one is around to see it, does it make a sound?","title":"Static extraction of Docker image artifacts","type":"posts"},{"content":"","date":"17 May 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"4 May 2024","externalUrl":null,"permalink":"/tags/pedal-steel/","section":"Tags","summary":"","title":"Pedal Steel","type":"tags"},{"content":"","date":"4 May 2024","externalUrl":null,"permalink":"/series/pedal-steel/","section":"Series","summary":"","title":"Pedal Steel","type":"series"},{"content":"","date":"4 May 2024","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"Over a year ago, my partner and I visited Bellingham, WA to shop for antiques. We went to Penny Lane Antique Mall first, since it was the most (Google) reviewed antique shop in the city. There was another antique shop next door, called Aladdin\u0026rsquo;s Antiques and Records. Although we didn\u0026rsquo;t plan to visit Aladdin\u0026rsquo;s, it was nearby so we went inside. As its name suggests, among other standard antique shop fare, Aladdin\u0026rsquo;s sold musical antiques - records and record players, accordions, sound systems, and antique instruments.\nLong story short, that afternoon I found myself fixated on a pile of zithers.\nWhat is a zither? # A zither is basically a stringed instrument where strings are stretched over a thin, flat body without extending past the body\u0026rsquo;s sounding box. Think of an acoustic guitar or a cello - these instruments are not zithers because their strings span the entire body of the instrument, past the sounding box. (Plus, neither instrument is thin, nor flat.)\nThere are several categories of zithers, so if this sounds interesting to you, the zither wikipedia page is great reading. (I think tube zithers are particularly cool.) To most, the prototypical zither looks like this:\n{}\nTo my untrained eye, this looks like a tiny harp with two sets of strings and a fretboard. This would be called a concert zither, and this type of zither is more popular in eastern Europe. In North America, chord zithers are more commonly found. I unearthed several chord zithers in Bellingham.\nChord zithers # Put simply, chord zithers make it easier to play chords. To me, a chord zither is distinguished by some special set of strings (or some special set of buttons) that are used to play chords instead of notes. The autoharp is a very well-known chord zither - if you\u0026rsquo;re into 60s pop, Do You Believe in Magic by The Lovin\u0026rsquo; Spoonful features the autoharp. The instrument certainly had its \u0026lsquo;moment\u0026rsquo; in the 60s.\nHidden beneath the autoharp\u0026rsquo;s \u0026ldquo;plate\u0026rdquo; of buttons, there are several bars affixed with soft pads. When an autoharp\u0026rsquo;s chord button is pressed, the bar is lowered onto the strings and pads will mute all strings except for the strings needed to produce a given chord.\nIn the 80s, Suzuki released the Omnichord, which is an electronic/synthesized version of an autoharp. Omnichords offer the same \u0026ldquo;button chording\u0026rdquo; functionality as the autoharp, but the two instruments sound very different. I only mention the omnichord because I think it sounds really, really cool.\nI\u0026rsquo;ve been looking for a new instrument to learn, so I introduced myself to the world of chord zithers when I got home from Bellingham. As I watched various Youtube videos and scraped the autoharp subreddit, I could see myself playing around with an autoharp, but I was missing a certain \u0026lsquo;wow\u0026rsquo; factor. I continued exploring the zither family and eventually ran across the tremoloa.\nTremoloa # The tremoloa is a fascinating instrument. The body of the tremoloa is dominated by a steel arm which supports a weighted rolling bar. The \u0026ldquo;melody string\u0026rdquo; running along the bottom of the instrument can be picked using a plectrum at the end of the arm. When the melody string is picked, the string vibrates against the weighted bar, which produces this ghostly, janky sound. Using the strings that run along the top of the instruments, accompanying notes/chords can be played with the left hand.\nIf the autoharp is niche, then the tremoloa is on another level of niche. This is a fretless instrument - these markings near the strings may seem fret-like, but from what I understand, they\u0026rsquo;re not very helpful when playing. I was disappointed to learn that tremoloa is so difficult to learn, because I\u0026rsquo;d found my \u0026lsquo;wow\u0026rsquo; factor in this barred stringed zither.\nIn my research, I found that the tremoloa was created as an attempt to market Hawaiian steel guitar to American consumers. (Though obviously, this instrument sounds nothing like Hawaiian steel guitar. Maybe call it a failed attempt?)\nWhat is steel guitar? # I\u0026rsquo;ve always been confused by this phrase \u0026lsquo;steel guitar\u0026rsquo;. In the past, I\u0026rsquo;ve played classical guitar - acoustic guitar, where the steel strings are replaced with softer nylon ones. So I wondered, is \u0026lsquo;steel guitar\u0026rsquo; just\u0026hellip; regular guitar?\nSteel guitar specifically refers to guitar that\u0026rsquo;s played with a bar (or some other object) pressed against its strings. I grew up listening to blues, so I\u0026rsquo;m familiar with this image of a crazy-looking guitar played with a metal tube on a finger of the fretting hand. This tube is pressed and slid along the fretboard, bringing a distinctly twangy timbre to notes picked with the other hand. Folks often refer to this style of steel guitar as \u0026ldquo;slide guitar\u0026rdquo;.\nThis form of steel guitar is usually played upright, meaning the body of the instrument is held against the body, strings facing outward. Hawaiian steel guitar is typically played with the guitar laid across the player\u0026rsquo;s lap, with one hand controlling the bar along the fretboard and another hand picking strings. As a more comfortable playing position,\nThis playing style gave rise to lap steel guitar.\nLap steel guitar\nWhat makes pedal steel so special? # The trouble with learning pedal steel # Relative to something like piano or clarinet, the pedal steel is an obscure instrument. Student models are expensive ($1000+). All models are heavy (50+ lbs). Variation between models makes it difficult to provide \u0026ldquo;one sizes fits all\u0026rdquo; instruction - are you trying to learn C6 tuning without any knee levers, or E9 tuning with 12 foot pedals and 8 knee levers?\nI\u0026rsquo;ve spoken with experienced pedal steel players who refer to the instrument as a \u0026ldquo;theory machine\u0026rdquo;.\n","date":"4 May 2024","externalUrl":null,"permalink":"/posts/pedal_steel_intro/","section":"Posts","summary":"An introduction to an enigmatic instrument.","title":"What is pedal steel guitar?","type":"posts"},{"content":"I\u0026rsquo;m a firm believer in the Internet\u0026rsquo;s power to serve as a repository of information and expertise. I write here because I love to share my learnings with others.\nI also believe that information should be accessible to all. Access to free, high-quality educational content enables individuals from all backgrounds to excel in engineering and related fields. I grew up with limited resources, and I wouldn\u0026rsquo;t be the person I am today without access to content like this.\nCredentials # I\u0026rsquo;ve been a Software Engineer at Microsoft since 2022. My background also includes some experience in full-stack web development, platform engineering, test automation, data analysis, and data visualization.\nMy preferred programming languages include Rust, TypeScript, C#\u0026hellip; Umm\u0026hellip;\n","externalUrl":null,"permalink":"/about/","section":"","summary":"I\u0026rsquo;m a firm believer in the Internet\u0026rsquo;s power to serve as a repository of information and expertise.","title":"About","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]